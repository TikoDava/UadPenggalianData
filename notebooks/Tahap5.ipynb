{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "Nta3Nsc1lSt2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# === Evaluasi Gabungan: TF-IDF, BERT, SVM ===\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import re\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "from transformers import AutoTokenizer, AutoModel\n",
        "import torch\n",
        "\n",
        "# === Normalisasi Pasal ===\n",
        "def normalize(text):\n",
        "    text = str(text).lower()\n",
        "    text = text.replace(\"republik indonesia\", \"ri\")\n",
        "    text = text.replace(\"undang-undang\", \"uu\")\n",
        "    text = text.replace(\"nomor\", \"no\")\n",
        "    text = re.sub(r\"[^a-z0-9\\s]\", \" \", text)\n",
        "    text = re.sub(r\"\\s+\", \" \", text).strip()\n",
        "    tokens = re.findall(r'pasal\\s+\\d+(?:\\s+ayat\\s*\\(\\d+\\))?|uu\\s*no\\s*\\d+', text)\n",
        "    return ' '.join(tokens)\n",
        "\n",
        "# === Load data kasus & prediksi ===\n",
        "df_raw = pd.read_csv(\"/content/drive/MyDrive/ProyekA/data/processed/cases.csv\")\n",
        "df_pred = pd.read_csv(\"/content/drive/MyDrive/ProyekA/data/results/predictions.csv\")\n",
        "\n",
        "# Normalisasi ground truth dan prediksi\n",
        "pred_df = df_pred.copy()\n",
        "pred_df[\"tfidf_pred\"] = pred_df[\"predicted_solution\"].apply(normalize)\n",
        "pred_df[\"bert_pred\"] = pred_df[\"predicted_solution\"].apply(normalize)\n",
        "pred_df[\"ground_truth\"] = pred_df[\"ground_truth\"].apply(normalize)\n",
        "\n",
        "# === TF-IDF Vectorizer for SVM ===\n",
        "df_raw = df_raw[df_raw['ringkasan_fakta'].notna() & df_raw['pasal'].notna()]\n",
        "df_raw[\"pasal_clean\"] = df_raw[\"pasal\"].apply(normalize)\n",
        "\n",
        "X = df_raw[\"ringkasan_fakta\"]\n",
        "y = df_raw[\"pasal_clean\"]\n",
        "vectorizer = TfidfVectorizer()\n",
        "X_vec = vectorizer.fit_transform(X)\n",
        "\n",
        "# Train/test split for SVM\n",
        "X_train, X_test, y_train, y_test = train_test_split(X_vec, y, test_size=0.2, random_state=42)\n",
        "svm = SVC(kernel=\"linear\")\n",
        "svm.fit(X_train, y_train)\n",
        "y_pred_svm = svm.predict(X_test)\n",
        "\n",
        "# === Evaluasi semua model ===\n",
        "def containment_score(y_true, y_pred):\n",
        "    return sum(yt in yp or yp in yt for yt, yp in zip(y_true, y_pred)) / len(y_true)\n",
        "\n",
        "svm_df = pd.DataFrame({\"y_true\": y_test, \"y_pred\": y_pred_svm})\n",
        "\n",
        "results = [\n",
        "    {\n",
        "        \"Model\": \"TF-IDF Retrieval\",\n",
        "        \"Accuracy\": containment_score(pred_df[\"ground_truth\"], pred_df[\"tfidf_pred\"])\n",
        "    },\n",
        "    {\n",
        "        \"Model\": \"BERT Retrieval\",\n",
        "        \"Accuracy\": containment_score(pred_df[\"ground_truth\"], pred_df[\"bert_pred\"])\n",
        "    },\n",
        "    {\n",
        "        \"Model\": \"SVM Classifier\",\n",
        "        \"Accuracy\": accuracy_score(svm_df[\"y_true\"], svm_df[\"y_pred\"]),\n",
        "        \"Precision\": precision_score(svm_df[\"y_true\"], svm_df[\"y_pred\"], average=\"macro\", zero_division=0),\n",
        "        \"Recall\": recall_score(svm_df[\"y_true\"], svm_df[\"y_pred\"], average=\"macro\", zero_division=0),\n",
        "        \"F1-score\": f1_score(svm_df[\"y_true\"], svm_df[\"y_pred\"], average=\"macro\", zero_division=0)\n",
        "    }\n",
        "]\n",
        "\n",
        "# Lengkapi kolom kosong dengan nilai akurasi\n",
        "for r in results:\n",
        "    r.setdefault(\"Precision\", r[\"Accuracy\"])\n",
        "    r.setdefault(\"Recall\", r[\"Accuracy\"])\n",
        "    r.setdefault(\"F1-score\", r[\"Accuracy\"])\n",
        "\n",
        "# Simpan hasil evaluasi ke CSV\n",
        "df_results = pd.DataFrame(results)\n",
        "df_results.to_csv(\"/content/drive/MyDrive/ProyekA/data/eval/retrieval_metrics.csv\", index=False)\n",
        "print(\"✅ Semua model berhasil dievaluasi dan disimpan.\")\n",
        "print(df_results.round(2))\n"
      ],
      "metadata": {
        "id": "8zZUrAZqlGYb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Plot hasil bar chart\n",
        "plt.figure(figsize=(8, 5))\n",
        "for metric in [\"Accuracy\", \"Precision\", \"Recall\", \"F1-score\"]:\n",
        "    plt.plot(df_results[\"Model\"], df_results[metric], marker='o', label=metric)\n",
        "\n",
        "plt.title(\"Perbandingan Performa Model (Containment Match)\")\n",
        "plt.ylabel(\"Skor\")\n",
        "plt.xlabel(\"Model\")\n",
        "plt.ylim(0, 1)\n",
        "plt.grid(True, linestyle=\"--\", alpha=0.5)\n",
        "plt.legend()\n",
        "plt.xticks(rotation=15)\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "AVfuJ9J0lIfK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Pastikan model sebagai index\n",
        "df_results_plot = df_results.set_index(\"Model\")[[\"Accuracy\", \"Precision\", \"Recall\", \"F1-score\"]]\n",
        "\n",
        "# Buat bar chart\n",
        "ax = df_results_plot.plot(kind=\"bar\", figsize=(10, 6), colormap=\"tab10\")\n",
        "plt.title(\"Evaluasi Kinerja Model Retrieval dan Klasifikasi\")\n",
        "plt.ylabel(\"Skor\")\n",
        "plt.ylim(0, 1.0)\n",
        "plt.xticks(rotation=15)\n",
        "plt.grid(axis=\"y\", linestyle=\"--\", alpha=0.7)\n",
        "plt.tight_layout()\n",
        "plt.legend(title=\"Metrik\")\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "p0nwgNpolLzB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"\\n=== ERROR ANALYSIS: PREDIKSI SALAH ===\")\n",
        "for _, row in df.iterrows():\n",
        "    y_true_n = normalize(row[\"ground_truth\"])\n",
        "    y_pred_n = normalize(row[\"predicted_solution\"])\n",
        "    if y_true_n not in y_pred_n and y_pred_n not in y_true_n:\n",
        "        print(f\"[✗] {row['query_id']} — Prediksi: {row['predicted_solution']} | Ground Truth: {row['ground_truth']}\")\n",
        "        print(f\"     Query: {row['query_text']}\")\n"
      ],
      "metadata": {
        "id": "xQ_4v5GulPHl"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}